{
  "window_size": 128,
  "total_steps": 100000,
  "save_every": 200,
  "batch_size": 4,
  "grad_accum_steps": 4,
  "lr": 0.0003,
  "gpu": 7,
  "d_model": 768,
  "n_layers": 12,
  "n_heads": 12,
  "mini_batch_size": 16,
  "ttt_lr": 1.0,
  "output_dir": "length_gen_w128_with_ckpts",
  "wandb_project": null
}